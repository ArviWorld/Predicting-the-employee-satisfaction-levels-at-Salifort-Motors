reticulate::repl_python()
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
df0 = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\DataHR_capstone_dataset.csv")
# Display first few rows of the dataframe
df0.head()
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
df.head()
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
print(df.head())
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
display(df.head())
install display
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
display(df.head())
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
print(df.head().to_string())
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
display(df.head().to_string())
py_install("ipython", envname = "~/.virtualenvs/r-reticulate")
reticulate::py_install("ipython", envname = "~/.virtualenvs/r-reticulate")
reticulate::repl_python()
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
display(df.head().to_string())
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
from tabulate import tabulate
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
print(tabulate(df.head(), headers='keys', tablefmt='github'))
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
from tabulate import tabulate
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
print(tabulate(df.head(), headers='keys', tablefmt='github'))
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
tabulate(df.head(), headers='keys', tablefmt='github')
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
df = pd.read_csv("D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Display first few rows of the dataframe
df.head().style.set_table_styles([
{'selector': 'th', 'props': [('font-weight', 'bold')]},
{'selector': 'td', 'props': [('text-align', 'center')]}
]).set_caption("HR Dataset Preview")
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
print(tabulate(df.head(), headers='keys', tablefmt='github'))
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
tabulate(df.head(), headers='keys')
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
print(tabulate(df.head(), headers='keys'))
# Gather basic information about the data
df.info()
# Gather basic information about the data
print(tabulate(df.info())
quit
# Gather basic information about the data
print(df.info())
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import io
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
from tabulate import tabulate
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str)
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str)
# Print the descriptive statistics
print(df.describe())
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
# Import packages
# Operational Packages
import numpy as np
import pandas as pd
import io
import pickle
# Visualization packages
import matplotlib.pyplot as plt
import seaborn as sns
from IPython.display import display
from tabulate import tabulate
# Modelling packages
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
#XGBoost
from xgboost import XGBClassifier
from xgboost import XGBRegressor
from xgboost import plot_importance
# Modelling evaluation and metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score,\
f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.tree import plot_tree
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
print(tabulate(df.head(), headers='keys', tablefmt='fancy_grid'))
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
print(tabulate(df.head(), headers='keys', tablefmt='html'))
# Load dataset into a dataframe
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)
# Load CSV
df = pd.read_csv(r"D:\Study\Machine Learning\Projects\R-Git\Completed projects for GitHub\Predicting-the-employee-satisfaction-levels-at-Salifort-Motors\Data\HR_capstone_dataset.csv")
# Format first 5 rows like a kable table
print(tabulate(df.head(), headers='keys', tablefmt='latex'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(tabulate(info_str, headers='keys', tablefmt='latex'))
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='latex'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(tabulate(info_str, headers='keys', tablefmt='github'))
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='latex'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(tabulate(info_str, headers='keys'))
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='latex'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str, headers='keys'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str)
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='latex'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str)
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='github'))
# Gather basic information about the data
# Create a StringIO buffer
buffer = io.StringIO()
# Capture the output of df.info() into the buffer
df.info(buf=buffer)
# Get the content from the buffer
info_str = buffer.getvalue()
# Print the content
print(info_str)
# Print the descriptive statistics
print(tabulate(df.describe(), headers='keys', tablefmt='simple'))
# Display all column names
df0.columns
# Display all column names
df.columns
# Rename columns as needed
df1 = df.copy()
df1 = df.rename(columns={'satisfaction_level':'satisfaction',
'last_evaluation':'last_eval',
'number_project':'#_projects',
'average_montly_hours':'avg_mon_hrs',
'time_spend_company':'tenure',
'Work_accident':'work_accident',
'promotion_last_5years':'promotion_<5yrs',
'Department':'department'
})
# Display all column names after the update
# Rename columns as needed
df1 = df.copy()
df1 = df.rename(columns={'satisfaction_level':'satisfaction',
'last_evaluation':'last_eval',
'number_project':'#_projects',
'average_montly_hours':'avg_mon_hrs',
'time_spend_company':'tenure',
'Work_accident':'work_accident',
'promotion_last_5years':'promotion_<5yrs',
'Department':'department'
})
# Display all column names after the update
df1.columns
# Rename columns as needed
df1 = df.copy()
df1 = df.rename(columns={'satisfaction_level':'satisfaction',
'last_evaluation':'last_eval',
'number_project':'#_projects',
'average_montly_hours':'avg_mon_hrs',
'time_spend_company':'tenure',
'Work_accident':'work_accident',
'promotion_last_5years':'promotion_<5yrs',
'Department':'department'
})
# Display all column names after the update
df1.columns
# Display all column names
df.columns
# Rename columns as needed
df1 = df.copy()
df1 = df.rename(columns={'satisfaction_level':'satisfaction',
'last_evaluation':'last_eval',
'number_project':'#_projects',
'average_montly_hours':'avg_mon_hrs',
'time_spend_company':'tenure',
'Work_accident':'work_accident',
'promotion_last_5years':'promotion_<5yrs',
'Department':'department'
})
# Display all column names after the update
df1.columns
# Check for missing values
df.isnull().sum()
# Check for missing values
df.isnull().sum()
# Check for duplicates
df.duplicated().sum()
# Check for duplicates
df.duplicated().sum()
# Inspect some rows containing duplicates as needed
df[df.duplicated()].head()
# Check for duplicates
df.duplicated().sum()
# Inspect some rows containing duplicates as needed
print(df[df.duplicated()].head())
# Drop duplicates and save resulting dataframe in a new variable as needed
df1 = df.drop_duplicates(keep='first')
# Display first few rows of new dataframe as needed
df1.head()
# Check for missing values
df1.isnull().sum()
# Check for duplicates
df1.duplicated().sum()
# Inspect some rows containing duplicates as needed
print(df1[df1.duplicated()].head())
reticulate::repl_python()
